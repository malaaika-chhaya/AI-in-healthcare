{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3edc6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "# Define transforms to be applied to the input images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((794, 801)),  # Resize the input images to the desired size\n",
    "    transforms.ToTensor(),  # Convert the input images to tensors\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),  # Normalize the input images\n",
    "])\n",
    "# Define the dataset object\n",
    "dataset_train = ImageFolder(root='C:/Users/bm112bioinformaticsl/OneDrive/Desktop/multi_task/S_transform/train_dataset/', transform=transform)\n",
    "dataset_test = ImageFolder(root='C:/Users/bm112bioinformaticsl/OneDrive/Desktop/multi_task/S_transform/test_dataset/', transform=transform)\n",
    "# Define the batch size and number of workers for data loading\n",
    "batch_size = 32\n",
    "num_workers = 4\n",
    "num_epochs=10\n",
    "# Define the data loader for training\n",
    "# train_loader = DataLoader(dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "# train_dataset, test_dataset = random_split(dataset, [int(0.5*dataset.__len__()), int(0.5*dataset.__len__())])\n",
    "train_loader = torch.utils.data.DataLoader(dataset=dataset_train, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=dataset_test, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a623ec36-60e6-4709-8451-18bc4e79c7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 1.172, Train Accuracy: 50.000%\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 78\u001b[0m\n\u001b[0;32m     75\u001b[0m     train_accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m*\u001b[39m correct \u001b[38;5;241m/\u001b[39m total\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Train Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Train Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 78\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mplot(num_epochs, train_loss)\n\u001b[0;32m     79\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpochs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     80\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "#device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, num_classes=2, embedding_dim=2):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.embedding_dim = embedding_dim\n",
    "        # Define CNN-2D layers\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        # Define MTL module with center loss\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dense_aux = nn.Linear(1267200, embedding_dim)\n",
    "        self.dense_aux_norm = nn.BatchNorm1d(embedding_dim)\n",
    "        self.centers = nn.Embedding(num_classes, embedding_dim)\n",
    "        # Define main classification task using sigmoid layer\n",
    "        self.dense_mi = nn.Linear(1267200, 1)\n",
    "        # Define auxiliary classification task\n",
    "        self.aux_task_output = nn.Linear(1267200, num_classes)\n",
    "        self.aux_task_output_normed = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        # CNN-2D layers\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool3(x)\n",
    "        # Flatten output of CNN-2D layers\n",
    "        x = self.flatten(x)\n",
    "        # MTL module with center loss\n",
    "        aux_out = self.dense_aux(x)\n",
    "        aux_out_norm = self.dense_aux_norm(aux_out)\n",
    "        center_loss = torch.mean(torch.square(aux_out_norm - self.centers(y)))\n",
    "        # Main and auxiliary task outputs\n",
    "        mi_out = torch.sigmoid(self.dense_mi(x))\n",
    "        aux_task_out = self.aux_task_output(x)\n",
    "        aux_task_out_normed = self.aux_task_output_normed(aux_task_out)\n",
    "        if y is not None:\n",
    "            return mi_out, aux_task_out_normed, center_loss\n",
    "        else:\n",
    "            return mi_out, aux_task_out_normed\n",
    "model = CNNModel(num_classes=2)\n",
    "alpha_weight = 0.5\n",
    "beta_weight = 0.7\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "def m2nn_loss(mi_true, aux_true, mi_pred, aux_pred, center_loss):\n",
    "    main_task_loss = F.cross_entropy(mi_pred, mi_true)\n",
    "#     aux_task_loss = F.cross_entropy(aux_pred, aux_true)\n",
    "    return alpha_weight*main_task_loss + beta_weight*center_loss\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images\n",
    "        labels = labels\n",
    "        optimizer.zero_grad()\n",
    "        mi_out, aux_task_out_normed, center_loss = model(images, labels)\n",
    "        loss = m2nn_loss(mi_true=labels.unsqueeze(1).float(), aux_true=labels, mi_pred=mi_out, aux_pred=aux_task_out_normed, center_loss=center_loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(aux_task_out_normed.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        train_accuracy = 100 * correct / total\n",
    "        \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.3f}, Train Accuracy: {train_accuracy:.3f}%\")\n",
    "    plt.plot(num_epochs, train_loss)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('train loss')\n",
    "        \n",
    "    plt.figure()\n",
    "    plt.plot(num_epochs, train_accuracy)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('train accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3ede7b8a-8e32-4025-8949-c8a951558254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Test Loss: 37.196, Test Accuracy: 75.000%\n",
      "Epoch 2/10, Test Loss: 336.824, Test Accuracy: 50.000%\n",
      "Epoch 3/10, Test Loss: 19.538, Test Accuracy: 50.000%\n",
      "Epoch 4/10, Test Loss: 60.867, Test Accuracy: 50.000%\n",
      "Epoch 5/10, Test Loss: 89.222, Test Accuracy: 50.000%\n",
      "Epoch 6/10, Test Loss: 29.434, Test Accuracy: 25.000%\n",
      "Epoch 7/10, Test Loss: 2.163, Test Accuracy: 50.000%\n",
      "Epoch 8/10, Test Loss: 3.638, Test Accuracy: 75.000%\n",
      "Epoch 9/10, Test Loss: 9.877, Test Accuracy: 50.000%\n",
      "Epoch 10/10, Test Loss: 13.035, Test Accuracy: 50.000%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (images, labels) in enumerate(test_loader):\n",
    "        images = images\n",
    "        labels = labels\n",
    "        optimizer.zero_grad()\n",
    "        mi_out, aux_task_out_normed, center_loss = model(images, labels)\n",
    "        loss = m2nn_loss(mi_true=labels.unsqueeze(1).float(), aux_true=labels, mi_pred=mi_out, aux_pred=aux_task_out_normed, center_loss=center_loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = torch.max(aux_task_out_normed.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        test_accuracy = 100 * correct / total\n",
    "        plt.plot(num_epochs, train_loss)\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('train loss')\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Test Loss: {test_loss:.3f}, Test Accuracy: {test_accuracy:.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c612ec-164b-4c1c-ac18-abc6fd2eed7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1e5d3c3-4066-459b-81f6-823ebd309847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for X, y in train_loader:\n",
    "    X = X\n",
    "    y = y\n",
    "\n",
    "print(X[1])\n",
    "from PIL import Image\n",
    "image_pil = Image.fromarray(X[0].permute(1, 2, 0).numpy().astype('uint8'))\n",
    "# show image using PIL\n",
    "image_pil.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f2d4acc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 0, 1, 0])\n",
      "tensor([[0.5025],\n",
      "        [0.5035],\n",
      "        [0.5035],\n",
      "        [0.5031]])\n",
      "tensor([[0.5012, 0.4988],\n",
      "        [0.5014, 0.4986],\n",
      "        [0.5024, 0.4976],\n",
      "        [0.5012, 0.4988]])\n",
      "Test Loss: 13.035, Test Accuracy: 50.000%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_loss = 0\n",
    "test_accuracy = 0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images\n",
    "        labels = labels\n",
    "        mi_out, aux_task_out_normed, _ = model(images, labels)\n",
    "        print(labels)\n",
    "        print(mi_out)\n",
    "        print(aux_task_out_normed)\n",
    "        # loss = m2nn_loss(mi_true=labels.unsqueeze(1).float(), aux_true=labels, mi_pred=mi_out, aux_pred=aux_task_out_normed, center_loss=None)\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = torch.max(aux_task_out_normed.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "test_accuracy = 100 * correct / total\n",
    "print(f\"Test Loss: {test_loss:.3f}, Test Accuracy: {test_accuracy:.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7cad9f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "y_predicted = []\n",
    "for i in mi_out:\n",
    "    if i.item()>0.4925:\n",
    "        y_predicted.append(int(1))\n",
    "    else:\n",
    "        y_predicted.append(int(i.item()))\n",
    "    \n",
    "    # if i>0.4925:\n",
    "    #     i=1\n",
    "mi_out = torch.tensor(y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b785508a-bbde-4156-9e3f-22a89b3b20b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1, 1])\n",
      "tensor([1, 0, 1, 0])\n",
      "[[0 2]\n",
      " [0 2]]\n"
     ]
    }
   ],
   "source": [
    "# print(mi_out)\n",
    "# Generate some example predictions and true labels\n",
    "y_pred = mi_out\n",
    "y_true = labels\n",
    "print(y_pred)\n",
    "print(y_true)\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e25155b9-8b12-49c7-a643-06b14ccba2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cafafc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
